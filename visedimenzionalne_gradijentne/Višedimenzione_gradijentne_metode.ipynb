{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "w3R5Klxfzxd8"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aeQDsH0ez-fE"
      },
      "outputs": [],
      "source": [
        "def funkcija(x):\n",
        "    # f(x,y) = x^2 + y^2\n",
        "    return x[0]**2 + x[1]**2\n",
        "\n",
        "def gradijent(x):\n",
        "    x = np.array(x).reshape(np.size(x))\n",
        "    return np.asarray([[2*x[0]], [2*x[1]]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xdi1bEEl0ep7",
        "outputId": "786fe4b4-2062-4a07-99cd-8c894448f7f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimum funkcije se nalazi u tacki [[-2.20885535e-05]\n",
            " [ 2.20885535e-05]] ,vrednost funkcije u toj tacki iznosi  [9.7580839e-10]\n"
          ]
        }
      ],
      "source": [
        "#izvod funkcije, pocetna tacka,learning grade, tolerancija, broj iteracija\n",
        "def gradijentni_metod(gradf, x0, gamma, epsilon, N):\n",
        "    x = np.array(x0).reshape(len(x0), 1)\n",
        "    for k in range(N):\n",
        "        g = gradf(x)\n",
        "        x = x - gamma*g\n",
        "        if np.linalg.norm(g) < epsilon:\n",
        "            break\n",
        "    return x\n",
        "\n",
        "optimum = gradijentni_metod(gradijent, x0=[-2, 2], gamma=0.15, epsilon=1e-4, N=100)\n",
        "vrednost_funkcije = funkcija(optimum)\n",
        "print(\"Optimum funkcije se nalazi u tacki\",optimum,\",vrednost funkcije u toj tacki iznosi \", vrednost_funkcije)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-REF2fCw12oI",
        "outputId": "1d52044f-c3f3-4082-f4b4-26b2d18143e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimum funkcije se nalazi u tacki [[-1.60127099e-05]\n",
            " [ 1.60127099e-05]] ,vrednost funkcije u toj tacki iznosi  [5.1281376e-10]\n"
          ]
        }
      ],
      "source": [
        "#izvod funkcije, pocetna tacka,learning grade, tolerancija,koliko verujemo prethodnoj brzini\n",
        " #                              broj iteracija\n",
        "def gradijentni_metod_sa_momentom(gradf, x0, gamma, epsilon, omega, N):\n",
        "    x = np.array(x0).reshape(len(x0), 1)\n",
        "    v = 0\n",
        "    for k in range(N):\n",
        "        g = gradf(x)\n",
        "        v = omega*v + gamma*g\n",
        "        x =  x - v\n",
        "        if np.linalg.norm(g) < epsilon:\n",
        "            break\n",
        "    return x\n",
        "optimum = gradijentni_metod_sa_momentom(gradijent, x0=[-2, 2], gamma=0.15, epsilon=1e-4, omega=0.1, N=100)\n",
        "vrednost_funkcije = funkcija(optimum)\n",
        "print(\"Optimum funkcije se nalazi u tacki\",optimum,\",vrednost funkcije u toj tacki iznosi \", vrednost_funkcije)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXuBBt172WK6",
        "outputId": "5f6277f7-e728-4b78-901e-0d45b64069f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimum funkcije se nalazi u tacki [[-2.43154053e-05]\n",
            " [ 2.43154053e-05]] ,vrednost funkcije u toj tacki iznosi  [1.18247787e-09]\n"
          ]
        }
      ],
      "source": [
        "#izvod funkcije, pocetna tacka,learning grade,neNula, tolerancija, broj iteracija\n",
        "def adagrad(gradf, x0, gamma, epsilon1, epsilon, N):\n",
        "    x = np.array(x0).reshape(len(x0), 1)\n",
        "    v = 0\n",
        "    G = 0\n",
        "    for k in range(N):\n",
        "        g = gradf(x)\n",
        "        G = G + np.multiply(g, g)\n",
        "        v = (gamma * g)/np.sqrt(G + epsilon1) #epsilon1 sluzi da G ne bude nula\n",
        "        x = x - v\n",
        "        if np.linalg.norm(g) < epsilon:\n",
        "            break\n",
        "    return x\n",
        "\n",
        "optimum = adagrad(gradijent, x0=[-1, 1], gamma=0.3, epsilon1=1e-8, epsilon=1e-4, N=100)\n",
        "vrednost_funkcije = funkcija(optimum)\n",
        "print(\"Optimum funkcije se nalazi u tacki\",optimum,\",vrednost funkcije u toj tacki iznosi \", vrednost_funkcije)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWk2ZkzJ2yeS",
        "outputId": "72f21a0e-9e4b-4251-ca56-fad4e8d28c56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimum funkcije se nalazi u tacki [[-1.17382043e-05]\n",
            " [ 9.84968239e-06]] ,vrednost funkcije u toj tacki iznosi  [2.34801683e-10]\n"
          ]
        }
      ],
      "source": [
        "#omega1 Stopa eksponencijalnog opadanja za procenu prvog momenta\n",
        "#omega2 Stopa eksponencijalnog opadanja za procenu drugog momenta\n",
        "#izvod funkcije, pocetna tacka,learning grade,neNula, tolerancija, broj iteracija\n",
        "def adam(gradf, x0, gamma, omega1, omega2, epsilon1, epsilon, N):\n",
        "    x = np.array(x0).reshape(len(x0), 1)\n",
        "    v = 1\n",
        "    m = 1\n",
        "    for k in range(N):\n",
        "        g = gradf(x)\n",
        "        m = omega1*m + (1-omega1)*g\n",
        "        v = omega2*v + (1-omega2)*np.multiply(g, g)\n",
        "        hat_v = np.abs(v/(1-omega2))\n",
        "        hat_m = m/(1-omega1)\n",
        "        x = x - gamma * hat_m/np.sqrt(hat_v + epsilon1)\n",
        "        if np.linalg.norm(g) < epsilon:\n",
        "            break\n",
        "    return x\n",
        "optimum = adam(gradijent, x0=[-1, 1], gamma=0.1,omega1=0.1, omega2=0.9, epsilon1=1e-8, epsilon=1e-4, N=100)\n",
        "vrednost_funkcije = funkcija(optimum)\n",
        "print(\"Optimum funkcije se nalazi u tacki\",optimum,\",vrednost funkcije u toj tacki iznosi \", vrednost_funkcije)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
